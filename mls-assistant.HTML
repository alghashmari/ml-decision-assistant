<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Professional ML Algorithm Decision Assistant</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css" crossorigin="anonymous">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js" crossorigin="anonymous"></script>
    <style>
        :root {
            --primary-color: #667eea;
            --secondary-color: #764ba2;
            --accent-color: #38a169;
            --warning-color: #ed8936;
            --danger-color: #e53e3e;
            --text-dark: #2d3748;
            --text-light: #4a5568;
            --bg-light: #f7fafc;
            --border-color: #e2e8f0;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            min-height: 100vh;
            color: var(--text-dark);
            line-height: 1.6;
        }
        .container { max-width: 1400px; margin: 0 auto; padding: 20px; }
        .header { text-align: center; margin-bottom: 40px; color: white; }
        .header h1 { font-size: 2.8rem; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); margin-bottom: 10px; }
        .header p { font-size: 1.3rem; opacity: 0.9; }
        .header .subtitle { font-size: 1rem; margin-top: 10px; background: rgba(255,255,255,0.1); padding: 10px 20px; border-radius: 25px; display: inline-block; }
        .main-content { display: grid; grid-template-columns: 420px 1fr; gap: 30px; }
        .input-panel, .results-panel {
            background: rgba(255, 255, 255, 0.98);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            backdrop-filter: blur(10px);
        }
        .section-title {
            font-size: 1.4rem;
            font-weight: 600;
            margin-bottom: 20px;
            color: var(--text-light);
            border-bottom: 3px solid var(--primary-color);
            padding-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .form-group { margin-bottom: 20px; }
        .form-group label { display: block; margin-bottom: 8px; font-weight: 600; }
        .form-group .description { font-size: 0.9rem; color: var(--text-light); margin-bottom: 8px; font-style: italic; }
        select, input[type="range"] {
            width: 100%;
            padding: 12px;
            border: 2px solid var(--border-color);
            border-radius: 10px;
            font-size: 1rem;
            transition: all 0.3s ease;
        }
        select:focus, input:focus {
            border-color: var(--primary-color);
            outline: none;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }
        .checkbox-group { display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin-top: 10px; }
        .checkbox-item { display: flex; align-items: center; gap: 8px; }
        .checkbox-item input[type="checkbox"] { transform: scale(1.2); }
        .range-display { text-align: center; font-weight: bold; color: var(--primary-color); margin-top: 5px; }
        .analyze-btn {
            width: 100%;
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            color: white;
            border: none;
            padding: 18px;
            border-radius: 15px;
            font-size: 1.3rem;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-top: 20px;
        }
        .analyze-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 35px rgba(102, 126, 234, 0.4);
        }
        .results-content { min-height: 300px; }
        .no-results, .loading { text-align: center; color: var(--text-light); font-style: italic; margin-top: 50px; }
        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid var(--primary-color);
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 20px auto;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        .recommendation-card {
            background: linear-gradient(135deg, var(--bg-light) 0%, #ffffff 100%);
            border-radius: 18px;
            margin-bottom: 25px;
            border-left: 6px solid;
            transition: all 0.4s ease;
            overflow: hidden;
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        }
        .recommendation-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 40px rgba(0,0,0,0.15);
        }
        .recommendation-card-header {
            padding: 25px;
            cursor: pointer;
            transition: background 0.3s ease;
        }
        .recommendation-card-header:hover {
            background: rgba(102, 126, 234, 0.05);
        }
        .recommendation-card-body {
            padding: 0 25px;
            max-height: 0;
            overflow: hidden;
            transition: all 0.5s ease-in-out;
        }
        .recommendation-card.active .recommendation-card-body {
            max-height: 2000px;
            padding-bottom: 25px;
        }
        .algo-name {
            font-size: 1.5rem;
            font-weight: bold;
            display: flex;
            align-items: center;
            gap: 15px;
        }
        .algo-score {
            padding: 8px 16px;
            border-radius: 25px;
            font-size: 1rem;
            color: white;
            font-weight: bold;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        .algo-type {
            background: rgba(102, 126, 234, 0.1);
            color: var(--primary-color);
            padding: 4px 12px;
            border-radius: 15px;
            font-size: 0.8rem;
            font-weight: 600;
        }
        .info-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 25px;
            margin-top: 20px;
        }
        .info-block h4 {
            color: var(--secondary-color);
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 8px;
            margin-bottom: 15px;
            font-size: 1.1rem;
        }
        .info-block ul {
            list-style: none;
            padding: 0;
        }
        .info-block li {
            margin-bottom: 12px;
            padding: 10px;
            background: rgba(102, 126, 234, 0.05);
            border-radius: 8px;
            border-left: 3px solid var(--primary-color);
        }
        .debug-section {
            background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%);
            border-left: 6px solid var(--warning-color);
            border-radius: 15px;
            padding: 25px;
            margin-top: 25px;
            box-shadow: 0 8px 25px rgba(237, 137, 54, 0.1);
        }
        .eval-section {
            background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%);
            border-left: 6px solid #3b82f6;
            border-radius: 15px;
            padding: 25px;
            margin-top: 25px;
            box-shadow: 0 8px 25px rgba(59, 130, 246, 0.1);
        }
        .techniques-section {
            background: linear-gradient(135deg, #f0fff4 0%, #dcfce7 100%);
            border-left: 6px solid var(--accent-color);
            border-radius: 15px;
            padding: 25px;
            margin-top: 25px;
            box-shadow: 0 8px 25px rgba(56, 161, 105, 0.1);
        }
        .debug-section h3, .eval-section h3, .techniques-section h3 {
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
            font-size: 1.3rem;
        }
        .katex { font-size: 1.1em; }
        .pro-tip {
            background: linear-gradient(135deg, #fef7ff 0%, #f3e8ff 100%);
            border: 2px solid #a855f7;
            border-radius: 12px;
            padding: 20px;
            margin-top: 20px;
            position: relative;
        }
        .pro-tip::before {
            content: "üí°";
            position: absolute;
            top: -15px;
            left: 20px;
            background: #a855f7;
            color: white;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.2rem;
        }
        .confidence-legend {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin-top: 20px;
            padding: 20px;
            background: rgba(255,255,255,0.8);
            border-radius: 12px;
        }
        .confidence-item {
            text-align: center;
            padding: 10px;
            border-radius: 8px;
        }
        @media (max-width: 1000px) {
            .main-content { grid-template-columns: 1fr; }
            .info-grid { grid-template-columns: 1fr; }
            .confidence-legend { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ Professional ML Algorithm Assistant</h1>
            <p>Data Science Consultancy Tool</p>
            <div class="subtitle">Based on Andrew Ng's Machine Learning Specialization + Advanced Techniques</div>
        </div>

        <div class="main-content">
            <div class="input-panel">
                <h2 class="section-title">üéØ 1. Problem Definition</h2>
                <div class="form-group">
                    <label for="problemType">Primary ML Task</label>
                    <div class="description">What is your main objective with this data?</div>
                    <select id="problemType">
                        <option value="">Select your task...</option>
                        <option value="regression">Regression (Predict continuous values)</option>
                        <option value="classification">Classification (Predict categories)</option>
                        <option value="clustering">Clustering (Find hidden groups)</option>
                        <option value="anomaly-detection">Anomaly Detection (Find outliers)</option>
                        <option value="dimensionality-reduction">Dimensionality Reduction (Reduce features)</option>
                        <option value="recommendation">Recommendation System</option>
                        <option value="reinforcement">Reinforcement Learning</option>
                    </select>
                </div>

                <h2 class="section-title">üìä 2. Data Characteristics</h2>
                <div class="form-group">
                    <label for="datasetSize">Dataset Size</label>
                    <div class="description">How much training data do you have?</div>
                    <select id="datasetSize">
                        <option value="small">Small (<10k samples)</option>
                        <option value="medium">Medium (10k-1M samples)</option>
                        <option value="large">Large (>1M samples)</option>
                    </select>
                </div>

                <div class="form-group">
                    <label for="featureCount">Number of Features</label>
                    <div class="description">How many input variables/columns do you have?</div>
                    <input type="range" id="featureCount" min="1" max="10000" value="50">
                    <div class="range-display" id="featureCountDisplay">50 features</div>
                </div>

                <div class="form-group">
                    <label>Data Quality & Characteristics</label>
                    <div class="description">Select all that apply to your dataset:</div>
                    <div class="checkbox-group">
                        <div class="checkbox-item">
                            <input type="checkbox" id="nonlinear">
                            <label for="nonlinear">Non-linear relationships</label>
                        </div>
                        <div class="checkbox-item">
                            <input type="checkbox" id="categorical">
                            <label for="categorical">Many categorical features</label>
                        </div>
                        <div class="checkbox-item">
                            <input type="checkbox" id="outliers">
                            <label for="outliers">Contains outliers</label>
                        </div>
                        <div class="checkbox-item">
                            <input type="checkbox" id="missing">
                            <label for="missing">Missing values present</label>
                        </div>
                        <div class="checkbox-item">
                            <input type="checkbox" id="imbalanced">
                            <label for="imbalanced">Imbalanced classes</label>
                        </div>
                        <div class="checkbox-item">
                            <input type="checkbox" id="feature-engineering">
                            <label for="feature-engineering">Needs feature engineering</label>
                        </div>
                    </div>
                </div>

                <h2 class="section-title">‚öñÔ∏è 3. Requirements</h2>
                <div class="form-group">
                    <label for="interpretability">Interpretability vs. Performance Trade-off</label>
                    <div class="description">How important is it to explain model decisions?</div>
                    <select id="interpretability">
                        <option value="high">High Interpretability (Explainable AI)</option>
                        <option value="medium">Balanced Approach</option>
                        <option value="low">Maximum Performance</option>
                    </select>
                </div>

                <h2 class="section-title">üîç 4. Current Status</h2>
                <div class="form-group">
                    <label for="performance">Diagnosed Performance Issue</label>
                    <div class="description">If you've already tried a model, what's the main issue?</div>
                    <select id="performance">
                        <option value="unknown">Starting fresh / Not sure</option>
                        <option value="high-bias">High Bias (Underfitting - poor on both train & test)</option>
                        <option value="high-variance">High Variance (Overfitting - good on train, poor on test)</option>
                        <option value="data-mismatch">Train/test data from different distributions</option>
                    </select>
                </div>

                <button class="analyze-btn" onclick="analyzeAndRecommend()">üéØ Get Professional Recommendations</button>
            </div>

            <div class="results-panel">
                <h2 class="section-title">üèÜ ML Strategy Recommendations</h2>
                <div id="results" class="results-content">
                    <div class="no-results">
                        Configure your ML problem characteristics to receive comprehensive, professional-grade algorithm recommendations with implementation guidance! üöÄ

                        <div class="confidence-legend">
                            <div class="confidence-item" style="background: var(--accent-color); color: white;">
                                <strong>High Match (70-100%)</strong><br>
                                Excellent fit for your problem
                            </div>
                            <div class="confidence-item" style="background: var(--warning-color); color: white;">
                                <strong>Medium Match (40-69%)</strong><br>
                                Good option with tuning
                            </div>
                            <div class="confidence-item" style="background: var(--danger-color); color: white;">
                                <strong>Low Match (0-39%)</strong><br>
                                Consider other options first
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

<script>
const algorithms = {
    'linear-regression': {
        name: 'Linear Regression',
        type: 'Supervised Learning',
        concepts: [
            '**Hypothesis Function:** $h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n$',
            '**Cost Function:** $J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2$',
            '**Optimization:** Gradient Descent: $\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta)$',
            '**Normal Equation:** $\\theta = (X^T X)^{-1} X^T y$ (for small feature sets)'
        ],
        tips: [
            '**Feature Scaling** is crucial when using gradient descent',
            'Add **polynomial features** to capture non-linear relationships',
            'Use **regularization** (Ridge/Lasso) to prevent overfitting',
            'Check **residual plots** to validate linear assumptions'
        ],
        when_to_use: 'Simple baseline, interpretable results needed, linear relationships suspected',
        pros: ['Highly interpretable', 'Fast training', 'No hyperparameters', 'Probabilistic predictions'],
        cons: ['Assumes linear relationships', 'Sensitive to outliers', 'Requires feature scaling']
    },
    'polynomial-regression': {
        name: 'Polynomial Regression',
        type: 'Supervised Learning',
        concepts: [
            '**Feature Expansion:** Create polynomial combinations: $x_1, x_1^2, x_1 x_2, x_2^2, ...$',
            '**Bias-Variance Tradeoff:** Higher degree = lower bias, higher variance',
            '**Regularization:** Essential to prevent overfitting: $J(\\theta) = MSE + \\lambda \\sum \\theta_j^2$'
        ],
        tips: [
            'Start with **degree 2-3**, rarely go beyond degree 4',
            '**Always use regularization** to combat overfitting',
            'Use **cross-validation** to select optimal polynomial degree',
            'Consider **spline methods** for very non-linear data'
        ],
        when_to_use: 'Non-linear relationships, still need interpretability',
        pros: ['Captures non-linearity', 'Still interpretable', 'Extends linear regression'],
        cons: ['Prone to overfitting', 'Computationally expensive', 'Curse of dimensionality']
    },
    'logistic-regression': {
        name: 'Logistic Regression',
        type: 'Supervised Learning',
        concepts: [
            '**Sigmoid Function:** $g(z) = \\frac{1}{1+e^{-z}}$ where $z = \\theta^T x$',
            '**Hypothesis:** $h_\\theta(x) = g(\\theta^T x)$ (probability between 0 and 1)',
            '**Cost Function:** $J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}\\log(h_\\theta(x^{(i)})) + (1-y^{(i)})\\log(1-h_\\theta(x^{(i)}))]$',
            '**Decision Boundary:** Predict 1 if $h_\\theta(x) \\geq 0.5$, else 0'
        ],
        tips: [
            'Outputs **probabilities**, not just classifications',
            'Use **regularization** (L1/L2) to prevent overfitting',
            'For multiclass: **One-vs-All** or **softmax regression**',
            'Check **classification threshold** - 0.5 may not be optimal'
        ],
        when_to_use: 'Binary/multiclass classification, need probability estimates',
        pros: ['Outputs probabilities', 'No assumptions about distributions', 'Less prone to outliers'],
        cons: ['Assumes linear decision boundary', 'Can struggle with complex relationships']
    },
    'decision-tree': {
        name: 'Decision Tree',
        type: 'Supervised Learning',
        concepts: [
            '**Information Gain:** $IG = H(S) - \\sum_{v} \\frac{|S_v|}{|S|} H(S_v)$',
            '**Entropy:** $H(S) = -\\sum_{i} p_i \\log_2(p_i)$',
            '**Gini Impurity:** Alternative splitting criterion: $Gini = 1 - \\sum_{i} p_i^2$',
            '**Pruning:** Remove branches to reduce overfitting'
        ],
        tips: [
            'Set **max_depth** and **min_samples_split** to prevent overfitting',
            '**No feature scaling** required - handles mixed data types well',
            'Provides **feature importance** rankings',
            'Use **ensemble methods** (Random Forest) for better performance'
        ],
        when_to_use: 'Mixed data types, need interpretability, feature selection',
        pros: ['Highly interpretable', 'Handles mixed data', 'No assumptions about data distribution'],
        cons: ['Prone to overfitting', 'Can be unstable', 'Biased toward features with many levels']
    },
    'random-forest': {
        name: 'Random Forest',
        type: 'Supervised Learning (Ensemble)',
        concepts: [
            '**Bootstrap Aggregating:** Train multiple trees on random subsets of data',
            '**Feature Randomness:** Each split considers random subset of features',
            '**Voting:** Classification: majority vote, Regression: average prediction',
            '**Out-of-Bag Error:** Use ~37% unused samples for validation'
        ],
        tips: [
            'Excellent **general-purpose algorithm** - often first choice',
            'Provides **feature importance** without risk of overfitting',
            'Use **~100-500 trees** for good balance of performance vs speed',
            'Less interpretable than single tree but more robust'
        ],
        when_to_use: 'General-purpose algorithm, mixed data types, need feature importance',
        pros: ['Excellent performance', 'Reduces overfitting', 'Handles missing values', 'Feature importance'],
        cons: ['Less interpretable', 'Memory intensive', 'Can overfit with noisy data']
    },
    'xgboost': {
        name: 'XGBoost (Gradient Boosting)',
        type: 'Supervised Learning (Ensemble)',
        concepts: [
            '**Gradient Boosting:** $F_m(x) = F_{m-1}(x) + \\gamma_m h_m(x)$',
            '**Objective Function:** $Obj = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{k=1}^{K} \\Omega(f_k)$',
            '**Regularization:** Built-in L1 and L2 regularization',
            '**Second-Order Optimization:** Uses both gradient and Hessian'
        ],
        tips: [
            'Often **best performance** on structured/tabular data',
            'Use **early stopping** to prevent overfitting',
            'Tune **learning rate, max_depth, n_estimators**',
            'Handle missing values and categorical features well'
        ],
        when_to_use: 'Competitions, maximum performance needed, structured data',
        pros: ['Excellent performance', 'Built-in regularization', 'Handles missing data', 'Feature importance'],
        cons: ['Complex hyperparameter tuning', 'Longer training time', 'Less interpretable']
    },
    'neural-network': {
        name: 'Neural Network',
        type: 'Supervised Learning (Deep Learning)',
        concepts: [
            '**Forward Propagation:** $a^{[l]} = g^{[l]}(W^{[l]} a^{[l-1]} + b^{[l]})$',
            '**Backpropagation:** $\\frac{\\partial J}{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} (a^{[l-1]})^T$',
            '**Activation Functions:** ReLU for hidden layers: $g(z) = \\max(0,z)$',
            '**Universal Approximation:** Can approximate any continuous function'
        ],
        tips: [
            'Requires **large amounts of data** (typically >10k samples)',
            'Use **proper weight initialization** (Xavier/He initialization)',
            'Apply **regularization** (dropout, batch norm, early stopping)',
            'Start simple (1-2 hidden layers) and increase complexity if needed'
        ],
        when_to_use: 'Large datasets, complex patterns, high-dimensional data',
        pros: ['Handles complex patterns', 'Flexible architecture', 'State-of-the-art performance'],
        cons: ['Requires large datasets', 'Black box', 'Computationally expensive', 'Many hyperparameters']
    },
    'svm': {
        name: 'Support Vector Machine',
        type: 'Supervised Learning',
        concepts: [
            '**Margin Maximization:** Find hyperplane with maximum margin',
            '**Support Vectors:** Data points closest to decision boundary',
            '**Kernel Trick:** $K(x_i, x_j) = \\phi(x_i)^T \\phi(x_j)$ maps to higher dimensions',
            '**C Parameter:** Trades off margin size vs training accuracy'
        ],
        tips: [
            '**Feature scaling** is essential for SVM performance',
            'Use **RBF kernel** for non-linear data, **linear kernel** for high-dimensional',
            'Tune **C and gamma** parameters carefully',
            'Works well with **high-dimensional data** (text, images)'
        ],
        when_to_use: 'High-dimensional data, robust to overfitting, medium-sized datasets',
        pros: ['Effective in high dimensions', 'Memory efficient', 'Versatile kernels'],
        cons: ['Slow on large datasets', 'Sensitive to feature scaling', 'No probability estimates']
    },
    'k-means': {
        name: 'K-Means Clustering',
        type: 'Unsupervised Learning',
        concepts: [
            '**Objective:** Minimize within-cluster sum of squares: $\\sum_{i=1}^{k} \\sum_{x \\in C_i} ||x - \\mu_i||^2$',
            '**Algorithm:** 1) Initialize centroids, 2) Assign points, 3) Update centroids, 4) Repeat',
            '**Elbow Method:** Plot cost vs K to find optimal number of clusters',
            '**Convergence:** Algorithm converges when centroids stop moving'
        ],
        tips: [
            'Use **Elbow Method** or **Silhouette Analysis** to choose K',
            'Run **multiple times** with different initializations',
            '**Scale features** before clustering',
            'Assumes **spherical clusters** of similar size'
        ],
        when_to_use: 'Customer segmentation, data exploration, dimensionality reduction preprocessing',
        pros: ['Simple and fast', 'Works well with spherical clusters', 'Scalable'],
        cons: ['Must specify K', 'Assumes spherical clusters', 'Sensitive to initialization']
    },
    'anomaly-detection': {
        name: 'Anomaly Detection (Gaussian)',
        type: 'Unsupervised Learning',
        concepts: [
            '**Gaussian Distribution:** Model each feature as $x_j \\sim N(\\mu_j, \\sigma_j^2)$',
            '**Probability:** $p(x) = \\prod_{j=1}^{n} p(x_j; \\mu_j, \\sigma_j^2)$',
            '**Anomaly Threshold:** Flag if $p(x) < \\epsilon$',
            '**Evaluation:** Use precision/recall on labeled anomaly examples'
        ],
        tips: [
            'Transform **non-Gaussian features** (log, square root)',
            'Use **cross-validation** to select threshold $\\epsilon$',
            'Consider **multivariate Gaussian** for correlated features',
            'Works best when anomalies are **rare** (<1% of data)'
        ],
        when_to_use: 'Fraud detection, network security, quality control',
        pros: ['No labeled anomalies needed', 'Interpretable probability scores', 'Fast inference'],
        cons: ['Assumes Gaussian distribution', 'Struggles with high-dimensional data']
    },
    'pca': {
        name: 'Principal Component Analysis',
        type: 'Unsupervised Learning',
        concepts: [
            '**Objective:** Find directions of maximum variance in data',
            '**Principal Components:** Eigenvectors of covariance matrix',
            '**Variance Explained:** Choose k components that retain ~95% of variance',
            '**Projection:** $z = U_{reduce}^T x$ where $U_{reduce}$ is k eigenvectors'
        ],
        tips: [
            '**Always scale features** before applying PCA',
            'Use **scree plot** to choose number of components',
            'PCA is **linear** - consider t-SNE/UMAP for non-linear reduction',
            'Components are **not interpretable** - linear combinations of features'
        ],
        when_to_use: 'Dimensionality reduction, data visualization, noise reduction',
        pros: ['Reduces dimensionality', 'Removes correlated features', 'Fast and interpretable'],
        cons: ['Linear transformation only', 'Components hard to interpret', 'Sensitive to scaling']
    },
    'recommender-system': {
        name: 'Collaborative Filtering',
        type: 'Supervised Learning',
        concepts: [
            '**Matrix Factorization:** $Y \\approx X \\Theta^T$ where X=user features, $\\Theta$=item features',
            '**Cost Function:** $J = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} (\\theta^{(j)T} x^{(i)} - y^{(i,j)})^2 + \\frac{\\lambda}{2} \\sum ||\\theta^{(j)}||^2 + \\frac{\\lambda}{2} \\sum ||x^{(i)}||^2$',
            '**Learning:** Alternating minimization or gradient descent',
            '**Prediction:** $\\hat{y}^{(i,j)} = \\theta^{(j)T} x^{(i)}$'
        ],
        tips: [
            'Use **regularization** to prevent overfitting learned features',
            'Handle **cold start problem** with content-based features',
            'Consider **implicit feedback** (clicks, views) not just ratings',
            'Combine with **content-based filtering** for hybrid systems'
        ],
        when_to_use: 'E-commerce, streaming platforms, social media',
        pros: ['Finds hidden patterns', 'No domain knowledge needed', 'Improves over time'],
        cons: ['Cold start problem', 'Sparse data challenges', 'Scalability issues']
    },
    'reinforcement-learning': {
        name: 'Reinforcement Learning',
        type: 'Reinforcement Learning',
        concepts: [
            '**Markov Decision Process:** States S, Actions A, Rewards R, Transition Probabilities P',
            '**Bellman Equation:** $V(s) = \\max_a \\sum_{s\'} P(s\'|s,a)[R(s,a,s\') + \\gamma V(s\')]$',
            '**Q-Learning:** $Q(s,a) \\leftarrow Q(s,a) + \\alpha[r + \\gamma \\max_{a\'} Q(s\',a\') - Q(s,a)]$',
            '**Policy:** $\\pi(s) = \\arg\\max_a Q(s,a)$ (greedy policy)'
        ],
        tips: [
            'Balance **exploration vs exploitation** with $\\epsilon$-greedy',
            'Use **experience replay** and **target networks** for stability',
            'Start with **simple environments** before complex ones',
            'Consider **policy gradient methods** for continuous action spaces'
        ],
        when_to_use: 'Game playing, robotics, autonomous systems, dynamic optimization',
        pros: ['Learns optimal strategies', 'No need for labeled data', 'Handles sequential decisions'],
        cons: ['Requires environment interaction', 'Sample inefficient', 'Complex to implement']
    }
};

const techniques = {
    'feature-scaling': {
        name: 'Feature Scaling',
        description: 'Standardization: $z = \\frac{x - \\mu}{\\sigma}$, Min-Max: $x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$',
        importance: 'Critical for gradient descent and distance-based algorithms'
    },
    'cross-validation': {
        name: 'Cross-Validation',
        description: 'K-fold CV partitions data into K subsets, trains on K-1, validates on 1',
        importance: 'Essential for unbiased model evaluation and hyperparameter tuning'
    },
    'regularization': {
        name: 'Regularization',
        description: 'L1: $\\lambda \\sum |\\theta_i|$, L2: $\\lambda \\sum \\theta_i^2$, Dropout, Early Stopping',
        importance: 'Prevents overfitting by controlling model complexity'
    },
    'feature-engineering': {
        name: 'Feature Engineering',
        description: 'Create polynomial features, interactions, domain-specific transformations',
        importance: 'Often more impactful than algorithm choice - domain expertise is key'
    },
    'ensemble-methods': {
        name: 'Ensemble Methods',
        description: 'Bagging (Random Forest), Boosting (XGBoost), Stacking, Voting',
        importance: 'Combines multiple models to improve performance and robustness'
    },
    'hyperparameter-tuning': {
        name: 'Hyperparameter Tuning',
        description: 'Grid Search, Random Search, Bayesian Optimization, Hyperband',
        importance: 'Optimizes model performance - can dramatically improve results'
    }
};

// Feature count display
document.getElementById('featureCount').addEventListener('input', function(e) {
    const value = parseInt(e.target.value);
    let display = `${value} features`;
    if (value > 1000) display += ' (High-dimensional)';
    else if (value > 100) display += ' (Medium-dimensional)';
    document.getElementById('featureCountDisplay').textContent = display;
});

function analyzeAndRecommend() {
    const results = document.getElementById('results');
    results.innerHTML = `
        <div class="loading">
            <div class="spinner"></div>
            <h3>Analyzing your ML problem...</h3>
            <p>Evaluating algorithms, techniques, and debugging strategies</p>
        </div>
    `;

    setTimeout(() => {
        const recommendations = getRecommendations();
        displayRecommendations(recommendations);
    }, 1500);
}

function getRecommendations() {
    // Get form inputs
    const inputs = {
        problemType: document.getElementById('problemType').value,
        datasetSize: document.getElementById('datasetSize').value,
        featureCount: parseInt(document.getElementById('featureCount').value),
        interpretability: document.getElementById('interpretability').value,
        performance: document.getElementById('performance').value,
        nonlinear: document.getElementById('nonlinear').checked,
        categorical: document.getElementById('categorical').checked,
        outliers: document.getElementById('outliers').checked,
        missing: document.getElementById('missing').checked,
        imbalanced: document.getElementById('imbalanced').checked,
        featureEngineering: document.getElementById('feature-engineering').checked
    };

    // Initialize algorithm scores
    let scores = {};
    Object.keys(algorithms).forEach(key => scores[key] = 40);

    // Problem type scoring
    if (inputs.problemType === 'regression') {
        scores['linear-regression'] += 30;
        scores['polynomial-regression'] += 25;
        scores['random-forest'] += 25;
        scores['xgboost'] += 30;
        scores['neural-network'] += 20;
        // Zero out non-applicable
        ['logistic-regression', 'svm', 'k-means', 'anomaly-detection', 'pca', 'recommender-system', 'reinforcement-learning'].forEach(k => scores[k] = 0);
    } else if (inputs.problemType === 'classification') {
        scores['logistic-regression'] += 30;
        scores['decision-tree'] += 25;
        scores['random-forest'] += 30;
        scores['xgboost'] += 35;
        scores['neural-network'] += 25;
        scores['svm'] += 25;
        // Zero out non-applicable
        ['linear-regression', 'polynomial-regression', 'k-means', 'anomaly-detection', 'pca', 'recommender-system', 'reinforcement-learning'].forEach(k => scores[k] = 0);
    } else if (inputs.problemType === 'clustering') {
        scores['k-means'] += 50;
        Object.keys(scores).forEach(k => { if (k !== 'k-means') scores[k] = 0; });
    } else if (inputs.problemType === 'anomaly-detection') {
        scores['anomaly-detection'] += 50;
        Object.keys(scores).forEach(k => { if (k !== 'anomaly-detection') scores[k] = 0; });
    } else if (inputs.problemType === 'dimensionality-reduction') {
        scores['pca'] += 50;
        Object.keys(scores).forEach(k => { if (k !== 'pca') scores[k] = 0; });
    } else if (inputs.problemType === 'recommendation') {
        scores['recommender-system'] += 50;
        Object.keys(scores).forEach(k => { if (k !== 'recommender-system') scores[k] = 0; });
    } else if (inputs.problemType === 'reinforcement') {
        scores['reinforcement-learning'] += 50;
        Object.keys(scores).forEach(k => { if (k !== 'reinforcement-learning') scores[k] = 0; });
    }

    // Data size adjustments
    if (inputs.datasetSize === 'large') {
        scores['neural-network'] += 25;
        scores['xgboost'] += 20;
        scores['random-forest'] += 15;
        scores['decision-tree'] -= 20;
        scores['linear-regression'] -= 10;
        scores['logistic-regression'] -= 10;
    } else if (inputs.datasetSize === 'small') {
        scores['linear-regression'] += 20;
        scores['logistic-regression'] += 20;
        scores['decision-tree'] += 15;
        scores['svm'] += 10;
        scores['neural-network'] -= 35;
        scores['xgboost'] -= 15;
    }

    // Feature count adjustments
    if (inputs.featureCount > 1000) {
        scores['pca'] += 30;
        scores['neural-network'] += 20;
        scores['svm'] += 20;
        scores['linear-regression'] += 15;
        scores['logistic-regression'] += 15;
        scores['decision-tree'] -= 25;
        scores['k-means'] -= 15;
    } else if (inputs.featureCount < 20) {
        scores['decision-tree'] += 15;
        scores['random-forest'] += 10;
        scores['linear-regression'] += 10;
        scores['logistic-regression'] += 10;
    }

    // Interpretability requirements
    if (inputs.interpretability === 'high') {
        scores['linear-regression'] += 35;
        scores['logistic-regression'] += 35;
        scores['decision-tree'] += 40;
        scores['polynomial-regression'] += 25;
        scores['neural-network'] -= 40;
        scores['xgboost'] -= 25;
        scores['random-forest'] -= 20;
        scores['svm'] -= 15;
    } else if (inputs.interpretability === 'low') {
        scores['neural-network'] += 30;
        scores['xgboost'] += 25;
        scores['random-forest'] += 20;
        scores['svm'] += 15;
    }

    // Data characteristics
    if (inputs.nonlinear) {
        scores['polynomial-regression'] += 30;
        scores['neural-network'] += 35;
        scores['xgboost'] += 25;
        scores['random-forest'] += 20;
        scores['svm'] += 25;
        scores['decision-tree'] += 15;
        scores['linear-regression'] -= 35;
        scores['logistic-regression'] -= 30;
    }

    if (inputs.categorical) {
        scores['decision-tree'] += 25;
        scores['random-forest'] += 30;
        scores['xgboost'] += 30;
        scores['linear-regression'] -= 25;
        scores['logistic-regression'] -= 20;
        scores['neural-network'] -= 15;
        scores['svm'] -= 20;
    }

    if (inputs.outliers) {
        scores['decision-tree'] += 20;
        scores['random-forest'] += 25;
        scores['svm'] += 15;
        scores['linear-regression'] -= 25;
        scores['logistic-regression'] -= 15;
        scores['k-means'] -= 20;
    }

    if (inputs.missing) {
        scores['decision-tree'] += 20;
        scores['random-forest'] += 25;
        scores['xgboost'] += 25;
        scores['linear-regression'] -= 30;
        scores['logistic-regression'] -= 25;
        scores['neural-network'] -= 20;
        scores['svm'] -= 25;
    }

    if (inputs.imbalanced) {
        scores['xgboost'] += 15;
        scores['random-forest'] += 10;
        scores['svm'] += 10;
        scores['neural-network'] += 10;
    }

    // Performance issue adjustments
    if (inputs.performance === 'high-bias') {
        scores['polynomial-regression'] += 25;
        scores['neural-network'] += 30;
        scores['xgboost'] += 25;
        scores['random-forest'] += 20;
        scores['svm'] += 20;
        scores['linear-regression'] -= 20;
        scores['logistic-regression'] -= 15;
    } else if (inputs.performance === 'high-variance') {
        scores['linear-regression'] += 25;
        scores['logistic-regression'] += 25;
        scores['decision-tree'] -= 30;
        scores['neural-network'] -= 25;
        scores['xgboost'] -= 15;
    }

    // Clamp scores and sort
    const recommendations = Object.entries(scores)
        .map(([key, score]) => ({
            algorithm: key,
            score: Math.max(0, Math.min(100, Math.round(score))),
            confidence: getConfidenceBand(score)
        }))
        .filter(r => r.score > 0)
        .sort((a, b) => b.score - a.score);

    // Get technique recommendations
    const techniqueRecs = getTechniqueRecommendations(inputs);

    return {
        algorithms: recommendations,
        techniques: techniqueRecs,
        inputs: inputs
    };
}

function getConfidenceBand(score) {
    if (score >= 70) return 'high';
    if (score >= 40) return 'medium';
    return 'low';
}

function getTechniqueRecommendations(inputs) {
    const recs = [];

    // Always recommend cross-validation
    recs.push({
        technique: 'cross-validation',
        priority: 'Critical',
        reason: 'Essential for reliable model evaluation and preventing overfitting'
    });

    // Feature scaling for certain algorithms
    if (['neural-network', 'svm', 'logistic-regression', 'linear-regression', 'k-means', 'pca'].some(algo =>
        inputs.problemType === 'regression' || inputs.problemType === 'classification' || inputs.problemType === 'clustering' || inputs.problemType === 'dimensionality-reduction')) {
        recs.push({
            technique: 'feature-scaling',
            priority: 'High',
            reason: 'Distance-based and gradient descent algorithms require feature scaling'
        });
    }

    // Regularization for overfitting
    if (inputs.performance === 'high-variance' || inputs.featureCount > 100) {
        recs.push({
            technique: 'regularization',
            priority: 'High',
            reason: 'High variance detected or high-dimensional data - regularization will help'
        });
    }

    // Feature engineering
    if (inputs.featureEngineering || inputs.performance === 'high-bias') {
        recs.push({
            technique: 'feature-engineering',
            priority: 'High',
            reason: 'Creating better features often has more impact than algorithm choice'
        });
    }

    // Hyperparameter tuning
    recs.push({
        technique: 'hyperparameter-tuning',
        priority: 'Medium',
        reason: 'Optimize model performance through systematic parameter search'
    });

    // Ensemble methods
    if (inputs.interpretability !== 'high') {
        recs.push({
            technique: 'ensemble-methods',
            priority: 'Medium',
            reason: 'Combine multiple models for improved performance and robustness'
        });
    }

    return recs;
}

function displayRecommendations({ algorithms: recommendations, techniques: techniqueRecs, inputs }) {
    const results = document.getElementById('results');

    if (!recommendations || recommendations.length === 0) {
        results.innerHTML = `
            <div class="no-results">
                <h3>‚ö†Ô∏è Configuration Incomplete</h3>
                <p>Please select a problem type to get personalized recommendations!</p>
            </div>
        `;
        return;
    }

    let html = '';

    // Algorithm recommendations
    recommendations.slice(0, 5).forEach((rec, index) => {
        const algo = algorithms[rec.algorithm];
        let color = rec.confidence === 'high' ? 'var(--accent-color)' :
                   rec.confidence === 'medium' ? 'var(--warning-color)' : 'var(--danger-color)';

        const medalEmoji = index === 0 ? 'ü•á' : index === 1 ? 'ü•à' : index === 2 ? 'ü•â' : `${index + 1}.`;

        html += `
            <div class="recommendation-card" style="border-color: ${color};" data-algo="${rec.algorithm}">
                <div class="recommendation-card-header">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <div class="algo-name">
                            <span style="font-size: 1.8rem;">${medalEmoji}</span>
                            ${algo.name}
                            <span class="algo-type">${algo.type}</span>
                        </div>
                        <div style="display: flex; align-items: center; gap: 10px;">
                            <span class="algo-score" style="background: ${color};">${rec.score}% Match</span>
                            <span style="font-size: 1.5rem;">üëÜ</span>
                        </div>
                    </div>
                    <div style="margin-top: 10px; color: var(--text-light); font-size: 0.9rem;">
                        ${algo.when_to_use}
                    </div>
                </div>
                <div class="recommendation-card-body">
                    <div class="info-grid">
                        <div class="info-block">
                            <h4>üßÆ Key Mathematical Concepts</h4>
                            <ul>
                                ${algo.concepts.map(concept => `<li>${concept}</li>`).join('')}
                            </ul>
                        </div>
                        <div class="info-block">
                            <h4>üí° Implementation Tips</h4>
                            <ul>
                                ${algo.tips.map(tip => `<li>${tip}</li>`).join('')}
                            </ul>
                        </div>
                    </div>
                    <div class="info-grid" style="margin-top: 20px;">
                        <div class="info-block">
                            <h4>‚úÖ Pros</h4>
                            <ul>
                                ${algo.pros.map(pro => `<li style="border-left-color: var(--accent-color);">${pro}</li>`).join('')}
                            </ul>
                        </div>
                        <div class="info-block">
                            <h4>‚ö†Ô∏è Cons</h4>
                            <ul>
                                ${algo.cons.map(con => `<li style="border-left-color: var(--warning-color);">${con}</li>`).join('')}
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        `;
    });

    // Essential ML techniques section
    if (techniqueRecs.length > 0) {
        html += `
            <div class="techniques-section">
                <h3>üîß Essential ML Techniques for Your Project</h3>
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px;">
        `;

        techniqueRecs.forEach(tech => {
            const techInfo = techniques[tech.technique];
            const priorityColor = tech.priority === 'Critical' ? 'var(--danger-color)' :
                                 tech.priority === 'High' ? 'var(--warning-color)' : 'var(--accent-color)';

            html += `
                <div style="background: rgba(255,255,255,0.9); border-radius: 12px; padding: 20px; border-left: 4px solid ${priorityColor};">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                        <h4 style="color: var(--text-dark); margin: 0;">${techInfo.name}</h4>
                        <span style="background: ${priorityColor}; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.8rem; font-weight: bold;">
                            ${tech.priority}
                        </span>
                    </div>
                    <div style="font-size: 0.9rem; color: var(--text-light); margin-bottom: 10px;">
                        ${techInfo.description}
                    </div>
                    <div style="font-size: 0.9rem; color: var(--text-dark); font-style: italic;">
                        üí° ${tech.reason}
                    </div>
                </div>
            `;
        });

        html += `</div></div>`;
    }

    // Debugging section
    const debugAdvice = getDebuggingAdvice(inputs.performance, recommendations[0]?.algorithm);
    if (debugAdvice) {
        html += debugAdvice;
    }

    // Evaluation metrics section
    const evalAdvice = getEvaluationAdvice(inputs.problemType);
    if (evalAdvice) {
        html += evalAdvice;
    }

    // Pro tip section
    html += `
        <div class="pro-tip">
            <h3 style="margin-top: 25px; color: #7c3aed;">üéØ Professional ML Strategy</h3>
            <div style="margin-top: 15px;">
                <p><strong>Start Simple:</strong> Begin with the highest-rated algorithm above, implement proper evaluation, then iterate.</p>
                <p><strong>Feature Engineering First:</strong> Often 10x more impactful than algorithm choice. Domain expertise is your competitive advantage.</p>
                <p><strong>Evaluation Strategy:</strong> Use the metrics below, implement cross-validation, and always have a holdout test set.</p>
                <p><strong>Documentation:</strong> Keep detailed records of experiments, hyperparameters, and results for reproducibility.</p>
            </div>
        </div>
    `;

    results.innerHTML = html;

    // Add click handlers for accordion and render LaTeX after content is loaded
    document.querySelectorAll('.recommendation-card-header').forEach(header => {
        header.addEventListener('click', () => {
            const card = header.parentElement;
            card.classList.toggle('active');

            // Render LaTeX after accordion opens (with small delay to ensure content is visible)
            if (card.classList.contains('active')) {
                setTimeout(() => renderAllKatex(), 100);
            }
        });
    });

    // Initial LaTeX rendering
    setTimeout(() => renderAllKatex(), 500);
}

function getDebuggingAdvice(performance, topAlgorithm) {
    if (performance === 'unknown') return '';

    let advice = [];
    let title = '';

    if (performance === 'high-bias') {
        title = 'üêû High Bias (Underfitting) Debug Strategy';
        advice = [
            '**Goal:** Increase model complexity to capture underlying patterns',
            '**More Features:** Engineer polynomial features, interactions, domain-specific features',
            '**Bigger Models:** Increase network size, tree depth, or use more sophisticated algorithms',
            '**Less Regularization:** Reduce Œª in L1/L2 regularization, increase dropout rate',
            '**Training:** Train longer, use larger learning rates (carefully)',
            '**Check:** Plot learning curves - both train and validation error should be high'
        ];

        if (topAlgorithm === 'linear-regression') {
            advice.push('**Linear ‚Üí Polynomial:** Add x¬≤, x¬≥, x‚ÇÅx‚ÇÇ features to capture non-linearity');
        }
        if (topAlgorithm === 'neural-network') {
            advice.push('**Neural Networks:** Add hidden layers/neurons, try different activations');
        }

    } else if (performance === 'high-variance') {
        title = 'üêû High Variance (Overfitting) Debug Strategy';
        advice = [
            '**Goal:** Reduce model complexity and improve generalization',
            '**More Data:** Get additional training examples (most effective solution)',
            '**Regularization:** Add L1/L2 penalty, dropout, early stopping, batch normalization',
            '**Simpler Models:** Reduce network size, limit tree depth, feature selection',
            '**Cross-Validation:** Use k-fold CV to get better performance estimates',
            '**Check:** Large gap between train accuracy (high) and validation accuracy (low)'
        ];

        if (topAlgorithm === 'decision-tree') {
            advice.push('**Trees:** Set max_depth, min_samples_split, min_samples_leaf parameters');
        }
        if (topAlgorithm === 'neural-network') {
            advice.push('**Neural Networks:** Add dropout layers, reduce model size, use batch norm');
        }

    } else if (performance === 'data-mismatch') {
        title = 'üêû Train/Dev Data Mismatch Debug Strategy';
        advice = [
            '**Goal:** Ensure training data represents the real-world distribution',
            '**Data Analysis:** Compare feature distributions between train/dev/test sets',
            '**Artificial Data Synthesis:** Create training data that matches dev set distribution',
            '**Transfer Learning:** Pre-train on large dataset, fine-tune on target distribution',
            '**Domain Adaptation:** Use techniques to bridge the gap between domains',
            '**Check:** Train error low, train-dev error low, but dev error high'
        ];
    }

    return advice.length > 0 ? `
        <div class="debug-section">
            <h3>${title}</h3>
            <ul style="list-style: none; padding: 0;">
                ${advice.map(item => `<li style="margin-bottom: 12px; padding: 12px; background: rgba(237, 137, 54, 0.1); border-radius: 8px; border-left: 3px solid var(--warning-color);">${item}</li>`).join('')}
            </ul>
        </div>
    ` : '';
}

function getEvaluationAdvice(problemType) {
    let metrics = [];
    let title = '';

    if (problemType === 'regression') {
        title = 'üìè Regression Evaluation Metrics';
        metrics = [
            '**Mean Squared Error (MSE):** $MSE = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})^2$ - Penalizes large errors heavily',
            '**Root Mean Squared Error (RMSE):** $RMSE = \\sqrt{MSE}$ - Same units as target variable',
            '**Mean Absolute Error (MAE):** $MAE = \\frac{1}{m}\\sum_{i=1}^{m}|\\hat{y}^{(i)} - y^{(i)}|$ - More robust to outliers',
            '**R-squared (R¬≤):** $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$ - Proportion of variance explained (0-1, higher better)',
            '**Cross-Validation:** Use 5-fold or 10-fold CV for reliable performance estimates'
        ];
    } else if (problemType === 'classification') {
        title = 'üìè Classification Evaluation Metrics';
        metrics = [
            '**Accuracy:** $\\frac{TP + TN}{TP + TN + FP + FN}$ - Good for balanced datasets only',
            '**Precision:** $\\frac{TP}{TP + FP}$ - "Of predicted positives, how many were correct?"',
            '**Recall (Sensitivity):** $\\frac{TP}{TP + FN}$ - "Of actual positives, how many did we find?"',
            '**F1-Score:** $F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$ - Harmonic mean, good for imbalanced data',
            '**ROC-AUC:** Area under ROC curve - measures ability to distinguish between classes',
            '**Confusion Matrix:** Visualize True/False Positives/Negatives for deeper insights',
            '**Stratified Cross-Validation:** Maintains class proportions in each fold'
        ];
    } else if (problemType === 'clustering') {
        title = 'üìè Clustering Evaluation Metrics';
        metrics = [
            '**Silhouette Score:** $s = \\frac{b - a}{\\max(a,b)}$ where a=intra-cluster distance, b=nearest-cluster distance',
            '**Elbow Method:** Plot within-cluster sum of squares vs K, look for "elbow"',
            '**Calinski-Harabasz Index:** Ratio of between-cluster to within-cluster dispersion',
            '**Davies-Bouldin Index:** Average similarity between clusters (lower is better)',
            '**Visual Inspection:** Plot clusters in 2D/3D space to validate meaningfulness'
        ];
    } else {
        return '';
    }

    return `
        <div class="eval-section">
            <h3>${title}</h3>
            <ul style="list-style: none; padding: 0;">
                ${metrics.map(metric => `<li style="margin-bottom: 12px; padding: 12px; background: rgba(59, 130, 246, 0.1); border-radius: 8px; border-left: 3px solid #3b82f6;">${metric}</li>`).join('')}
            </ul>
            <div style="margin-top: 20px; padding: 15px; background: rgba(59, 130, 246, 0.05); border-radius: 8px;">
                <strong>üí° Evaluation Best Practices:</strong>
                <ul style="margin-top: 10px; padding-left: 20px;">
                    <li>Always use a separate test set that you never touch during development</li>
                    <li>Use cross-validation for model selection and hyperparameter tuning</li>
                    <li>For imbalanced data, focus on precision, recall, and F1-score rather than accuracy</li>
                    <li>Plot learning curves to diagnose bias/variance issues</li>
                </ul>
            </div>
        </div>
    `;
}

function renderAllKatex() {
    // Check if KaTeX is loaded
    if (typeof katex === 'undefined') {
        console.warn('KaTeX not loaded, skipping LaTeX rendering');
        return;
    }

    // Find all elements that might contain LaTeX and render them
    document.querySelectorAll('.recommendation-card-body li, .debug-section li, .eval-section li').forEach(element => {
        const text = element.innerHTML;

        // Look for LaTeX delimited by $ symbols
        const latexRegex = /\$([^$]+)\$/g;
        if (latexRegex.test(text)) {
            try {
                const renderedText = text.replace(latexRegex, (match, latex) => {
                    return katex.renderToString(latex.trim(), {
                        throwOnError: false,
                        displayMode: false,
                        strict: false
                    });
                });
                element.innerHTML = renderedText;
            } catch (e) {
                console.warn('LaTeX rendering error for:', latex, e);
                // Keep original text if rendering fails
            }
        }
    });

    // Also render any block math (display mode)
    document.querySelectorAll('.recommendation-card-body li, .debug-section li, .eval-section li').forEach(element => {
        const text = element.innerHTML;

        // Look for display math delimited by $ symbols
        const displayMathRegex = /\$\$([^$]+)\$\$/g;
        if (displayMathRegex.test(text)) {
            try {
                const renderedText = text.replace(displayMathRegex, (match, latex) => {
                    return katex.renderToString(latex.trim(), {
                        throwOnError: false,
                        displayMode: true,
                        strict: false
                    });
                });
                element.innerHTML = renderedText;
            } catch (e) {
                console.warn('LaTeX rendering error for display math:', latex, e);
            }
        }
    });
}
</script>
</body>
</html>